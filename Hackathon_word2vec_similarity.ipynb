{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the work directory\n",
    "import os\n",
    "os.getcwd()\n",
    "# os.chdir('/')  change the work directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\User\\\\Desktop\\\\Hackathon\\\\camp_dataset\\\\sim_question_train.txt\", encoding = \"utf-8\") as f:\n",
    "    dat_train = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\User\\\\Desktop\\\\Hackathon\\\\camp_dataset\\\\sim_question_test.txt\", encoding = \"utf-8\") as f:\n",
    "    dat_test = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import gensim\n",
    "from gensim import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the function that split the data\n",
    "def split_train_data (text):\n",
    "    text_pd = pd.DataFrame(text)\n",
    "    text_pd.columns = [\"question\"]\n",
    "    question = text_pd[\"question\"].str.split(\"@@@@@\", expand = True)\n",
    "    text_pd[\"q1\"] = question[0]\n",
    "    text_pd[\"q2\"] = question[1]\n",
    "    text_pd[\"pair\"] = question[2]\n",
    "    text_pd.drop(\"question\", axis = 1, inplace =True)\n",
    "    return text_pd\n",
    "\n",
    "def split_test_data (text):\n",
    "    text_pd = pd.DataFrame(text)\n",
    "    text_pd.columns = [\"question\"]\n",
    "    question = text_pd[\"question\"].str.split(\"@@@@@\", expand = True)\n",
    "    text_pd[\"q1\"] = question[0]\n",
    "    text_pd[\"q2\"] = question[1]\n",
    "    text_pd.drop(\"question\", axis = 1, inplace =True)\n",
    "    return text_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = split_train_data(dat_train)\n",
    "data_test = split_test_data(dat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first remove the \\n in the train pair column\n",
    "data_train[\"pair\"] = data_train[\"pair\"].replace(r\"\\n\", \"\",regex = True)\n",
    "data_train[\"pair\"] = data_train[\"pair\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to clean data\n",
    "def clean_data (data):\n",
    "    # remove the meaningless signs\n",
    "    for column in data:\n",
    "        # remove $\n",
    "        data[column] = data[column].str.replace(\"$\", \"\")  \n",
    "        \n",
    "        #remove the numbers, the alphabets\n",
    "        #data[column] = data[column].str.replace(\"\\d+\", \"\").str.replace(r'[A-Za-z]+', '') \n",
    "        \n",
    "        # remove the calculation sign (like +, -, *, (, { )\n",
    "        data[column] = data[column].apply(lambda x: x.replace(\"+\", \"\").replace(\"-\", \"\").replace(\"=\", \"\").replace(\"*\", \"\"))\n",
    "        data[column] = data[column].apply(lambda x: x.replace(\"{\",\"\").replace(\"}\",\"\").replace(\"、\",\"\").replace(\"：\",\"\").replace(\"？\",\"\").replace(\"（\",\"\").replace(\"）\",\"\").replace(\"，\",\"\").replace(\".\",\"\"))\n",
    "        data[column] = data[column].apply(lambda x: x.replace(\"(\",\"\").replace(\")\",\"\").replace(\"?\",\"\").replace(\"。\",\"\").replace(\"|\",\"\").replace(\",\",\"\").replace(\"^\",\"\").replace(\"；\",\"\"))\n",
    "        \n",
    "        # remove the white space and \\xa0 within sentences\n",
    "        data[column] = data[column].str.replace(\" \", \"\").str.replace(u'\\xa0', \"\")\n",
    "        \n",
    "        # remove white spaces\n",
    "        data[column] = data[column].str.strip() \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean dataset\n",
    "data_train = clean_data(data_train)\n",
    "data_test = clean_data(data_test)\n",
    "#data_train.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define tokenize function\n",
    "def tokenize_question (data, column):\n",
    "    q_words = []\n",
    "    for i in data[column]:\n",
    "        segs = jieba.cut(i)\n",
    "        result = \" \".join(segs).split(\" \")\n",
    "        q_words.append(result)\n",
    "    return q_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the train and test data\n",
    "q1_words = tokenize_question(data_train, \"q1\")\n",
    "q2_words = tokenize_question(data_train,\"q2\")\n",
    "q1_test_words = tokenize_question(data_test, \"q1\")\n",
    "q2_test_words = tokenize_question(data_test, \"q2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_combine = []\n",
    "vic = dict()\n",
    "for i in q1_words:\n",
    "    words_combine.append(i)\n",
    "for i in q2_words:\n",
    "    words_combine.append(i)\n",
    "for i in q1_test_words:\n",
    "    words_combine.append(i)\n",
    "for i in q2_test_words:\n",
    "    words_combine.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use model to train word embedding\n",
    "#model1 = gensim.models.Word2Vec(words_combine, size=100, window=5, min_count=1)    ## accuracy = 0.690\n",
    "#model2 = gensim.models.Word2Vec(words_combine, size=200, window=5, min_count=1)     ## accuracy = 0.688\n",
    "#model3 = gensim.models.Word2Vec(words_combine, size=150, window=5, min_count=1)      ## accuracy = 0.6878\n",
    "#model4 = gensim.models.Word2Vec(words_combine, size=100, window=8, min_count=1)    ## accuracy = 0.708\n",
    "model5 = gensim.models.Word2Vec(words_combine, size=100, window=10, min_count=1)    ## accuracy = 0.711\n",
    "#model6 = gensim.models.Word2Vec(words_combine, size=100, window=12, min_count=1)    ## accuracy = 0.716"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use model on each pair question\n",
    "pred_dic = {\"q1\":q1_words, \"q2\":q2_words}\n",
    "pred_df = pd.DataFrame(pred_dic)\n",
    "def compare_similarity(x, y):\n",
    "    return model1.n_similarity(x,y).item()\n",
    "\n",
    "pred_df['similarity'] = pred_df.apply(lambda row: compare_similarity(row['q1'], row['q2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate the accuracy\n",
    "pred_df[\"pred_pair\"] = pred_df[\"similarity\"].apply(lambda x: 1 if x >=0.5 else 0)\n",
    "pred_df[\"true_pair\"] = data_train[\"pair\"].astype(str).astype(int)\n",
    "result = pred_df[pred_df[\"true_pair\"] == pred_df[\"pred_pair\"]]\n",
    "accuracy = len(result)/len(pred_df)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict test set\n",
    "test_data_dic = {\"q1\":q1_test_words, \"q2\":q2_test_words}\n",
    "test_data_df = pd.DataFrame(test_data_dic)\n",
    "def compare_similarity(x, y):\n",
    "    return model5.n_similarity(x,y).item()\n",
    "\n",
    "test_data_df['similarity'] = test_data_df.apply(lambda row: compare_similarity(row['q1'], row['q2']), axis=1)\n",
    "test_data_df[\"pred_pair\"] = test_data_df[\"similarity\"].apply(lambda x: 1 if x >=0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
